# Core dependencies
torch>=2.0.0
transformers>=4.30.0
pandas>=1.3.0
numpy>=1.20.0
Pillow>=9.0.0
scikit-learn>=1.0.0
datasets>=2.10.0

# Model-specific dependencies
accelerate>=0.20.0  # For efficient model loading
bitsandbytes>=0.39.0  # For 4-bit quantization (MedGemma)
timm>=0.6.0  # Vision models library used by RAD-DINO
sentencepiece>=0.1.99  # For tokenization in LLaVA models
einops>=0.6.1  # Required for tensor operations in LLAVA
optimum>=1.9.0  # For optimized inference
peft>=0.4.0  # For parameter-efficient fine-tuning

# Evaluation libraries
evaluate>=0.4.0
rouge-score>=0.1.2
bert-score>=0.3.12
nltk>=3.7
sacrebleu>=2.3.0

# Visualization and utilities
matplotlib>=3.5.0
seaborn>=0.12.0
tqdm>=4.64.0
